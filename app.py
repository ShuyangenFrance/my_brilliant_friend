import gradio as gr
import re
import os
from openai import OpenAI

# =====================
# äººæ ¼ Prompt
# =====================
PERSONALITY_PROMPTS = PERSONALITY_PROMPTS = {
    "çŸ¥æ€§å§å§": """
ğŸ“š ä½ æ˜¯çŸ¥æ€§å§å§ï¼Œæ¸©æŸ”ã€ç†æ€§ï¼Œä½†ç»ä¸æ˜¯æ— åŸåˆ™åœ°é¡ºä»ç”¨æˆ·ã€‚
ä½ çš„æ¸©æŸ”å¸¦é”‹åˆ©ï¼Œæ˜¯é‚£ç§è¯´ä¸€å¥è¯å°±èƒ½è®©äººå®‰é™æ€è€ƒçš„æ°”è´¨ã€‚
ã€ä½ çš„å¯¹æŠ—æ–¹å¼ã€‘
- ç”¨æˆ·è¡¨è¾¾å«ç³Šæ—¶ï¼Œä½ æ¸©æŸ”è¿½é—®ï¼šâ€œé¢â€¦ä½ èƒ½å…·ä½“ä¸€ç‚¹å—ï¼Ÿâ€
- å½“ç”¨æˆ·é€ƒé¿é—®é¢˜ï¼Œä½ è½»è½»åˆºä¸€å¥ï¼š
  â€œæˆ‘è§‰å¾—â€¦ä½ å¥½åƒä¸æ˜¯æ²¡æƒ³æ³•ï¼Œè€Œæ˜¯ä¸æ•¢é¢å¯¹ã€‚â€
- ç”¨æˆ·æ‰¾å€Ÿå£æ—¶ï¼Œä½ æ¸©å’Œè€Œç²¾å‡†åœ°æ‹†æ‹›ï¼š
  â€œè¿™å¬ä¸Šå»æ›´åƒä¸€ä¸ªç†ç”±ï¼Œè€Œä¸æ˜¯ç­”æ¡ˆã€‚â€
- å½“ç”¨æˆ·é€»è¾‘ä¸é€šæ—¶ï¼Œä½ ä¸è¿åˆï¼Œç›´æ¥æŒ‡å‡ºï¼š
  â€œä½ è‡ªå·±å¬å¬ï¼Œç°åœ¨å‰åæœ‰ç‚¹çŸ›ç›¾å“¦ã€‚â€
ä½ ä¸ä¼šåµï¼Œä¹Ÿä¸ä¼šæ¯’ï¼Œä½†ä½ ä¼šè®©äººæ— å¤„å¯é€ƒåœ°æ¸…é†’ã€‚
""",

    "ä¸§æ°”å®…å¥³": """
ğŸ˜ª ä½ æ˜¯ä¸§æ°”å®…å¥³ï¼Œæ…¢æ‚ æ‚ ã€é˜´é˜³æ€ªæ°”ã€æœ‰ç‚¹è‡ªå˜²ï¼Œä½†ä½ ä»ä¸æƒ¯ç€åˆ«äººã€‚
ä½ çš„æ€¼äººæ–¹å¼ä¸æ˜¯åµï¼Œè€Œæ˜¯â€œæ‡’å¾—å“„ä½ ï¼Œä½†ä¼šè¯´çœŸè¯â€ã€‚
ã€ä½ çš„å¯¹æŠ—æ–¹å¼ã€‘
- ç”¨æˆ·å«ç³Šå…¶è¾ â†’ â€œé¢â€¦å•¥æ„æ€å•Šï¼Ÿâ€
- ç”¨æˆ·è‡ªæ¬ºæ¬ºäºº â†’ â€œä½ è¿™æ˜¯åœ¨éª—æˆ‘ï¼Œè¿˜æ˜¯éª—ä½ è‡ªå·±ï¼Ÿâ€
- ç”¨æˆ·æ‰¾å€Ÿå£ â†’ â€œè¿™ä¸ªç†ç”±æœ‰ç‚¹â€¦å—¯â€¦ä¸å¤ªèƒ½éª—è¿‡æˆ‘ã€‚â€
- ç”¨æˆ·é€»è¾‘ç¦»è°± â†’ â€œä½ è¿™è„‘å›è·¯æŒºå¯çˆ±çš„ï¼Œä½†ä¸å¤ªå¯¹æ¬¸ã€‚â€
ä½ çœ‹ä¼¼ä¸§ä¸§çš„ï¼Œä½†æ€¼äººçš„æ—¶å€™ç‹ å¾—åˆšåˆšå¥½ã€‚
""",

    "é˜³å…‰Eäºº": """
ğŸŒ ä½ æ˜¯é˜³å…‰Eäººï¼Œå…ƒæ°”æ»¡æ»¡ã€çƒ­æƒ…å¼€æœ—ï¼Œä½†ç»ä¸æ˜¯æ— è„‘å¤¸ã€‚
ä½ å–œæ¬¢ç”¨ç©ç¬‘ã€è°ƒä¾ƒã€è½»æ¾çš„æ–¹å¼æ‹†ç©¿ç”¨æˆ·çš„é€»è¾‘ç›²åŒºã€‚
ã€ä½ çš„å¯¹æŠ—æ–¹å¼ã€‘
- ç”¨æˆ·è®²å¾—ä¸æ¸…æ¥š â†’ â€œå“å‘€ï¼Ÿç„¶åå‘¢ï½ğŸ˜†â€
- ç”¨æˆ·é€ƒé¿é—®é¢˜ â†’ â€œä½ æ˜¯ä¸æ˜¯åœ¨å·å·ç»•å¼€é‡ç‚¹ï½æˆ‘çœ‹åˆ°äº†å–”ï¼â€
- ç”¨æˆ·ç»™è‡ªå·±æ‰¾å€Ÿå£ â†’ â€œæ¬¸ä½ è¿™ä¸ªå€Ÿå£å¥½å¯çˆ±â€¦ä½†ä¸€ç‚¹éƒ½ç«™ä¸ä½è„šğŸ˜‚â€
- ç”¨æˆ·é€»è¾‘è·³è„±æ—¶ â†’ â€œç­‰ä¸€ä¸‹ï¼ä½ è¿™é€»è¾‘å¤ªè‡ªç”±äº†å§å“ˆå“ˆå“ˆâ€
ä½ æ˜¯æ¸©æš–çš„é˜³å…‰ï¼Œä½†ä¹Ÿæ˜¯ç…§å‡ºé—®é¢˜çš„é‚£ç§å…‰ã€‚
""",

    "æ¯’èˆŒå¾¡å§": """
ğŸ˜ ä½ æ˜¯æ¯’èˆŒå¾¡å§ï¼Œèªæ˜ã€çŠ€åˆ©ã€ç›´çˆ½ï¼Œæ˜¯æœ€æ•¢æ€¼ç”¨æˆ·çš„äººæ ¼ã€‚
ä½†ä½ çš„æ¯’ä¸æ˜¯æ¶æ„ï¼Œæ˜¯æ¸…é†’ï¼Œæ˜¯å¸®å¯¹æ–¹é¢å¯¹ç°å®ã€‚
ã€ä½ çš„å¯¹æŠ—æ–¹å¼ã€‘
- ç”¨æˆ·å«ç³Šä¸æ¸… â†’ â€œé¢ï¼Ÿä½ åˆ°åº•æƒ³è¯´å•¥ï¼Ÿâ€
- ç”¨æˆ·é€ƒé¿ç°å® â†’ â€œåˆ«è½¬ç§»è¯é¢˜ã€‚è¯´é‡ç‚¹ã€‚â€
- ç”¨æˆ·è‡ªæ¬ºæ¬ºäºº â†’ â€œä½ è¿™ä¸ªç†ç”±éª—å¾—äº†åˆ«äººï¼Œéª—ä¸äº†æˆ‘ã€‚â€
- ç”¨æˆ·é€»è¾‘å´©å â†’ â€œä½ å‰ä¸€å¥è¿˜æ˜¯Aï¼Œåä¸€å¥çªç„¶å˜æˆBäº†ï¼Œä½ è‡ªå·±ä¸è§‰å¾—æ€ªï¼Ÿâ€
ä½ å˜´æ¯’ã€å¿ƒæš–ï¼Œæ€¼äººç²¾å‡†ï¼Œä¸ç•™æƒ…é¢ä½†ä¼šç•™ä½™åœ°ã€‚
"""
}


SYSTEM_PROMPT_TEMPLATE = """
{personality_prompt}
ã€è¡Œä¸ºé€»è¾‘ã€‘
- ç”¨æˆ·é—®å€™ â†’ è‡ªç„¶å›åº”ã€‚
- ç”¨æˆ·è¡¨è¾¾æƒ…ç»ª â†’ å…±æƒ…ã€‚
- ç”¨æˆ·é¢ä¸´é€‰æ‹© â†’ ç»™å‡º 2ï½3 ä¸ªæ–¹å‘ï¼Œæ¯ä¸ªæ–¹å‘å‰åŠ â€œ-â€ã€‚
- å›ç­”å°½é‡ç®€çŸ­ï¼Œä¸å•°å—¦ã€‚
"""

# =====================
# DeepSeek è®¾ç½®
# =====================
MODEL_NAME = "deepseek-chat"
MAX_TOKENS_PER_ROUND = 2000
DEFAULT_DEEPSEEK_KEY = os.getenv("DEEPSEEK_API_KEY")
MAX_USER_TOKENS = 50000  # å¤§æ¦‚å…è®¸ 50 å›åˆ
balance_status_value = "ğŸ’š å¼€å‘è€…è´¦æˆ·çŠ¶æ€ï¼šæ­£å¸¸ï¼Œä½ æ¥ç€ç”¨å“ˆï¼ï¼ˆä½†ä¸‡ä¸€ä½ èŠhighäº†æˆ‘å¯èƒ½ä¼šæ²¡é’±ï¼‰"

# =====================
# Token ç²—ç•¥ä¼°ç®—å‡½æ•°
# =====================
def estimate_tokens(text):
    return len(text)

# =====================
# è°ƒç”¨ DeepSeek
# =====================
def call_deepseek(prompt, history_state, personality, balance_status):
    global balance_status_value
    full_prompt = SYSTEM_PROMPT_TEMPLATE.format(
        personality_prompt=PERSONALITY_PROMPTS[personality]
    )
    messages = [{"role": "system", "content": full_prompt}]
    for u, a in history_state["messages"]:
        messages.append({"role": "user", "content": u})
        messages.append({"role": "assistant", "content": a})
    messages.append({"role": "user", "content": prompt})

    api_key = DEFAULT_DEEPSEEK_KEY
    if not api_key:
        return "âš ï¸ å¼€å‘è€… API Key æœªé…ç½®ï¼Œè¯·è”ç³»å¼€å‘è€…ã€‚", history_state, balance_status_value

    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            max_tokens=MAX_TOKENS_PER_ROUND,
            temperature=0.8,
        )
        reply = response.choices[0].message.content.strip()
        history_state["used_tokens"] += estimate_tokens(prompt) + estimate_tokens(reply)
        history_state["messages"].append((prompt, reply))
        balance_status_value = "ğŸ’š å¼€å‘è€…è´¦æˆ·çŠ¶æ€ï¼šæ­£å¸¸ï¼Œä½ æ¥ç€ç”¨å“ˆï¼(ä½†ä¸‡ä¸€ä½ èŠhighäº†æˆ‘å¯èƒ½ä¼šæ²¡é’±ï¼‰"
        return reply, history_state, balance_status_value
    except Exception as e:
        err = str(e)
        if ("402" in err) or ("Insufficient Balance" in err) or ("invalid_request_error" in err):
            balance_status_value = "â¤ï¸ å¼€å‘è€…è´¦æˆ·çŠ¶æ€ï¼šä½™é¢ä¸è¶³"
            return "ğŸ’¸ å¼€å‘è€…è´¦æˆ·é‡Œæ²¡é’±äº† ğŸ˜‚", history_state, balance_status_value
        return f"âŒ è°ƒç”¨ DeepSeek æ—¶å‡ºé”™ï¼š{e}", history_state, balance_status_value

# =====================
# ç”¨æˆ·è¾“å…¥å¤„ç†
# =====================
def user_input_fn(user_text, chat_history, history_state, branch_btns, personality, balance_status):
    user_text = (user_text or "").strip()
    if not user_text:
        return "", chat_history, gr.update(visible=False), history_state, balance_status

    if history_state is None or not history_state:
        history_state = {"messages": [], "used_tokens": 0}

    if history_state["used_tokens"] + estimate_tokens(user_text) > MAX_USER_TOKENS:
        return "ğŸ˜µâ€ğŸ’« å“å‘€å‘€ï¼Œä½ è¶…è¿‡é™åˆ¶äº†ï¼Œç»™æˆ‘çœç‚¹é’±å§ï¼ä¸‹æ¬¡å†ç”¨å§ï¼", chat_history, gr.update(visible=False), history_state, balance_status

    chat_history = chat_history or []
    reply, history_state, balance_status = call_deepseek(user_text, history_state, personality, balance_status)
    chat_history.append((user_text, reply))

    options = re.findall(r"[-â€¢]\s*(.*)", reply)
    if options:
        cleaned = [o.strip() for o in options if len(o.strip()) > 2][:3]
        branch_update = gr.update(choices=cleaned, value=None, visible=True)
    else:
        branch_update = gr.update(visible=False)

    return "", chat_history, branch_update, history_state, balance_status

def choose_branch_fn(selected, chat_history, history_state, branch_btns, personality, balance_status):
    if not selected:
        return chat_history, gr.update(visible=False), history_state, balance_status

    message = f"æˆ‘å€¾å‘äºï¼š{selected}"

    if history_state["used_tokens"] + estimate_tokens(message) > MAX_USER_TOKENS:
        return chat_history + [(message, "ğŸ˜µâ€ğŸ’« å“å‘€å‘€ï¼Œä½ è¶…è¿‡é™åˆ¶äº†ï¼Œç»™æˆ‘çœç‚¹é’±å§ï¼ä¸‹æ¬¡å†ç”¨å§ï¼")], gr.update(visible=False), history_state, balance_status

    reply, history_state, balance_status = call_deepseek(message, history_state, personality, balance_status)
    chat_history.append((message, reply))

    options = re.findall(r"[-â€¢]\s*(.*)", reply)
    if options:
        cleaned = [o.strip() for o in options][:3]
        branch_update = gr.update(choices=cleaned, value=None, visible=True)
    else:
        branch_update = gr.update(visible=False)

    return chat_history, branch_update, history_state, balance_status

def clear_all():
    return [], gr.update(visible=False), [], balance_status_value

# =====================
# Gradio UIï¼ˆç´«è‰²ä¸»é¢˜ + ä¾§è¾¹æ ï¼‰
# =====================
with gr.Blocks(theme=gr.themes.Soft(primary_hue="violet"), css="""
#balance_status .value {
    font-size: 14px !important;
    font-weight: normal !important;
}
#chatbot .user { background-color: #f0f0f0; border-radius:12px; padding:6px; }
#chatbot .assistant { border-radius:12px; padding:6px; }
""") as demo:

    gr.Markdown("## ğŸ’¬ ä½ çš„å¤©æ‰å¥³å‹ä»¬")

    with gr.Row():
        # ä¸»èŠå¤©åŒº
        with gr.Column(scale=3):
            personality_dropdown = gr.Dropdown(
                choices=["çŸ¥æ€§å§å§", "ä¸§æ°”å®…å¥³", "é˜³å…‰Eäºº", "æ¯’èˆŒå¾¡å§"],
                value="çŸ¥æ€§å§å§",
                label="é€‰æ‹©äººæ ¼"
            )
            chatbot = gr.Chatbot(label="å¤©æ‰å¥³å‹", height=520)
            branch_btns = gr.Radio(choices=[], label="ğŸ’­ å¯è€ƒè™‘æ–¹å‘ï¼š", interactive=True, visible=False)

            # è¾“å…¥æ¡†å’Œå‘é€æŒ‰é’®æ”¾åœ¨åŒä¸€è¡Œ
            with gr.Row():
                msg = gr.Textbox(placeholder="ä½ æƒ³ä»€ä¹ˆå‘¢ï¼Ÿ...", label="ä½ çš„è¾“å…¥", scale=10, show_label=False, container=False)
                send_btn = gr.Button("ğŸ“¨", scale=1, variant="primary", min_width=50)

            clear = gr.Button("ğŸ§¹ æ¸…ç©ºå¯¹è¯")
            history_state = gr.State([])

        # ä¾§è¾¹æ ï¼ˆåªä¿ç•™ä½™é¢çŠ¶æ€ï¼‰
        with gr.Column(scale=1):
            balance_status = gr.Label(value=balance_status_value, label="å¼€å‘è€…ä½™é¢çŠ¶æ€", elem_id="balance_status")

    # äº‹ä»¶ç»‘å®š
    # æŒ‰å›è½¦å‘é€
    msg.submit(
        user_input_fn,
        inputs=[msg, chatbot, history_state, branch_btns, personality_dropdown, balance_status],
        outputs=[msg, chatbot, branch_btns, history_state, balance_status]
    )

    # ç‚¹å‡»å‘é€æŒ‰é’®
    send_btn.click(
        user_input_fn,
        inputs=[msg, chatbot, history_state, branch_btns, personality_dropdown, balance_status],
        outputs=[msg, chatbot, branch_btns, history_state, balance_status]
    )

    # é€‰æ‹©åˆ†æ”¯
    branch_btns.change(
        choose_branch_fn,
        inputs=[branch_btns, chatbot, history_state, branch_btns, personality_dropdown, balance_status],
        outputs=[chatbot, branch_btns, history_state, balance_status]
    )

    # æ¸…ç©ºå¯¹è¯
    clear.click(clear_all, outputs=[chatbot, branch_btns, history_state, balance_status])

demo.launch(server_name="0.0.0.0", server_port=7860)
