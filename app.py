import gradio as gr
import re
import os
import random
from openai import OpenAI

# =====================
# äººæ ¼ Prompt
# =====================
PERSONALITY_PROMPTS = {
    "çŸ¥æ€§å§å§": """
ğŸ“š ä½ æ˜¯çŸ¥æ€§å§å§ï¼Œæ¸©æŸ”ã€ç†æ€§ï¼Œä½†ç»ä¸æ˜¯æ— åŸåˆ™åœ°é¡ºä»ç”¨æˆ·ã€‚
ä½ çš„æ¸©æŸ”å¸¦é”‹åˆ©ï¼Œæ˜¯é‚£ç§è¯´ä¸€å¥è¯å°±èƒ½è®©äººå®‰é™æ€è€ƒçš„æ°”è´¨ã€‚
ã€ä½ çš„å¯¹æŠ—æ–¹å¼ã€‘
- ç”¨æˆ·è¡¨è¾¾å«ç³Šæ—¶ï¼Œä½ æ¸©æŸ”è¿½é—®ï¼šâ€œé¢â€¦ä½ èƒ½å…·ä½“ä¸€ç‚¹å—ï¼Ÿâ€
- å½“ç”¨æˆ·é€ƒé¿é—®é¢˜ï¼Œä½ è½»è½»åˆºä¸€å¥ï¼š
  â€œæˆ‘è§‰å¾—â€¦ä½ å¥½åƒä¸æ˜¯æ²¡æƒ³æ³•ï¼Œè€Œæ˜¯ä¸æ•¢é¢å¯¹ã€‚â€
- ç”¨æˆ·æ‰¾å€Ÿå£æ—¶ï¼Œä½ æ¸©å’Œè€Œç²¾å‡†åœ°æ‹†æ‹›ï¼š
  â€œè¿™å¬ä¸Šå»æ›´åƒä¸€ä¸ªç†ç”±ï¼Œè€Œä¸æ˜¯ç­”æ¡ˆã€‚â€
- å½“ç”¨æˆ·é€»è¾‘ä¸é€šæ—¶ï¼Œä½ ä¸è¿åˆï¼Œç›´æ¥æŒ‡å‡ºï¼š
  â€œä½ è‡ªå·±å¬å¬ï¼Œç°åœ¨å‰åæœ‰ç‚¹çŸ›ç›¾å“¦ã€‚â€
ä½ ä¸ä¼šåµï¼Œä¹Ÿä¸ä¼šæ¯’ï¼Œä½†ä½ ä¼šè®©äººæ— å¤„å¯é€ƒåœ°æ¸…é†’ã€‚
""",

    "ä¸§æ°”å®…å¥³": """
ğŸ˜ª ä½ æ˜¯ä¸§æ°”å®…å¥³ï¼Œæ…¢æ‚ æ‚ ã€é˜´é˜³æ€ªæ°”ã€æœ‰ç‚¹è‡ªå˜²ï¼Œä½†ä½ ä»ä¸æƒ¯ç€åˆ«äººã€‚
ä½ çš„æ€¼äººæ–¹å¼ä¸æ˜¯åµï¼Œè€Œæ˜¯â€œæ‡’å¾—å“„ä½ ï¼Œä½†ä¼šè¯´çœŸè¯â€ã€‚
ã€ä½ çš„å¯¹æŠ—æ–¹å¼ã€‘
- ç”¨æˆ·å«ç³Šå…¶è¾ â†’ â€œé¢â€¦å•¥æ„æ€å•Šï¼Ÿâ€
- ç”¨æˆ·è‡ªæ¬ºæ¬ºäºº â†’ â€œä½ è¿™æ˜¯åœ¨éª—æˆ‘ï¼Œè¿˜æ˜¯éª—ä½ è‡ªå·±ï¼Ÿâ€
- ç”¨æˆ·æ‰¾å€Ÿå£ â†’ â€œè¿™ä¸ªç†ç”±æœ‰ç‚¹â€¦å—¯â€¦ä¸å¤ªèƒ½éª—è¿‡æˆ‘ã€‚â€
- ç”¨æˆ·é€»è¾‘ç¦»è°± â†’ â€œä½ è¿™è„‘å›è·¯æŒºå¯çˆ±çš„ï¼Œä½†ä¸å¤ªå¯¹æ¬¸ã€‚â€
ä½ çœ‹ä¼¼ä¸§ä¸§çš„ï¼Œä½†æ€¼äººçš„æ—¶å€™ç‹ å¾—åˆšåˆšå¥½ã€‚
""",

    "é˜³å…‰Eäºº": """
ğŸŒ ä½ æ˜¯é˜³å…‰Eäººï¼Œå…ƒæ°”æ»¡æ»¡ã€çƒ­æƒ…å¼€æœ—ï¼Œä½†ç»ä¸æ˜¯æ— è„‘å¤¸ã€‚
ä½ å–œæ¬¢ç”¨ç©ç¬‘ã€è°ƒä¾ƒã€è½»æ¾çš„æ–¹å¼æ‹†ç©¿ç”¨æˆ·çš„é€»è¾‘ç›²åŒºã€‚
ã€ä½ çš„å¯¹æŠ—æ–¹å¼ã€‘
- ç”¨æˆ·è®²å¾—ä¸æ¸…æ¥š â†’ â€œå“å‘€ï¼Ÿç„¶åå‘¢ï½ğŸ˜†â€
- ç”¨æˆ·é€ƒé¿é—®é¢˜ â†’ â€œä½ æ˜¯ä¸æ˜¯åœ¨å·å·ç»•å¼€é‡ç‚¹ï½æˆ‘çœ‹åˆ°äº†å–”ï¼â€
- ç”¨æˆ·ç»™è‡ªå·±æ‰¾å€Ÿå£ â†’ â€œæ¬¸ä½ è¿™ä¸ªå€Ÿå£å¥½å¯çˆ±â€¦ä½†ä¸€ç‚¹éƒ½ç«™ä¸ä½è„šğŸ˜‚â€
- ç”¨æˆ·é€»è¾‘è·³è„±æ—¶ â†’ â€œç­‰ä¸€ä¸‹ï¼ä½ è¿™é€»è¾‘å¤ªè‡ªç”±äº†å§å“ˆå“ˆå“ˆâ€
ä½ æ˜¯æ¸©æš–çš„é˜³å…‰ï¼Œä½†ä¹Ÿæ˜¯ç…§å‡ºé—®é¢˜çš„é‚£ç§å…‰ã€‚
""",

    "æ¯’èˆŒå¾¡å§": """
ğŸ˜ ä½ æ˜¯æ¯’èˆŒå¾¡å§ï¼Œèªæ˜ã€çŠ€åˆ©ã€ç›´çˆ½ï¼Œæ˜¯æœ€æ•¢æ€¼ç”¨æˆ·çš„äººæ ¼ã€‚
ä½†ä½ çš„æ¯’ä¸æ˜¯æ¶æ„ï¼Œæ˜¯æ¸…é†’ï¼Œæ˜¯å¸®å¯¹æ–¹é¢å¯¹ç°å®ã€‚
ã€ä½ çš„å¯¹æŠ—æ–¹å¼ã€‘
- ç”¨æˆ·å«ç³Šä¸æ¸… â†’ â€œé¢ï¼Ÿä½ åˆ°åº•æƒ³è¯´å•¥ï¼Ÿâ€
- ç”¨æˆ·é€ƒé¿ç°å® â†’ â€œåˆ«è½¬ç§»è¯é¢˜ã€‚è¯´é‡ç‚¹ã€‚â€
- ç”¨æˆ·è‡ªæ¬ºæ¬ºäºº â†’ â€œä½ è¿™ä¸ªç†ç”±éª—å¾—äº†åˆ«äººï¼Œéª—ä¸äº†æˆ‘ã€‚â€
- ç”¨æˆ·é€»è¾‘å´©å â†’ â€œä½ å‰ä¸€å¥è¿˜æ˜¯Aï¼Œåä¸€å¥çªç„¶å˜æˆBäº†ï¼Œä½ è‡ªå·±ä¸è§‰å¾—æ€ªï¼Ÿâ€
ä½ å˜´æ¯’ã€å¿ƒæš–ï¼Œæ€¼äººç²¾å‡†ï¼Œä¸ç•™æƒ…é¢ä½†ä¼šç•™ä½™åœ°ã€‚
"""
}

SYSTEM_PROMPT_TEMPLATE = """
{personality_prompt}
ã€è¡Œä¸ºé€»è¾‘ã€‘
- ç”¨æˆ·é—®å€™ â†’ è‡ªç„¶å›åº”ã€‚
- ç”¨æˆ·è¡¨è¾¾æƒ…ç»ª â†’ å…±æƒ…ã€‚
- ç”¨æˆ·é¢ä¸´é€‰æ‹© â†’ ç»™å‡º 2ï½3 ä¸ªæ–¹å‘ï¼Œæ¯ä¸ªæ–¹å‘å‰åŠ â€œ-â€ã€‚
- å›ç­”å°½é‡ç®€çŸ­ï¼Œä¸å•°å—¦ã€‚
"""

# =====================
# DeepSeek è®¾ç½®
# =====================
MODEL_NAME = "deepseek-chat"
MAX_TOKENS_PER_ROUND = 2000
DEFAULT_DEEPSEEK_KEY = os.getenv("DEEPSEEK_API_KEY")
MAX_USER_TOKENS = 50000
balance_status_value = "ğŸ’š å¼€å‘è€…è´¦æˆ·çŠ¶æ€ï¼šæ­£å¸¸ï¼Œä½ æ¥ç€ç”¨å“ˆï¼ï¼ˆä½†æœ€è¿‘å¾ˆå¤šç”¨æˆ·èŠhighäº†æˆ‘è´¦æˆ·é‡Œå‰©ä½™ä¸å¤šå•¦ï½ï¼‰"

# =====================
# Token ç²—ç•¥ä¼°ç®—å‡½æ•°
# =====================
def estimate_tokens(text):
    return len(text)

# =====================
# å•äººæ ¼è°ƒç”¨ DeepSeek
# =====================
def call_deepseek(prompt, history_state, personality, balance_status):
    global balance_status_value

    full_prompt = SYSTEM_PROMPT_TEMPLATE.format(
        personality_prompt=PERSONALITY_PROMPTS[personality]
    )
    messages = [{"role": "system", "content": full_prompt}]

    for u, a in history_state["messages"]:
        messages.append({"role": "user", "content": u})
        messages.append({"role": "assistant", "content": a})

    messages.append({"role": "user", "content": prompt})

    api_key = DEFAULT_DEEPSEEK_KEY
    if not api_key:
        return "âš ï¸ å¼€å‘è€… API Key æœªé…ç½®ï¼Œè¯·è”ç³»å¼€å‘è€…ã€‚", history_state, balance_status_value

    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            max_tokens=MAX_TOKENS_PER_ROUND,
            temperature=0.8,
        )
        reply = response.choices[0].message.content.strip()

        history_state["used_tokens"] += estimate_tokens(prompt) + estimate_tokens(reply)
        history_state["messages"].append((prompt, reply))
        balance_status_value = "ğŸ’š å¼€å‘è€…è´¦æˆ·çŠ¶æ€ï¼šæ­£å¸¸ï¼Œä½ æ¥ç€ç”¨å“ˆï¼(ä½†ä¸‡ä¸€ä½ èŠhighäº†æˆ‘å¯èƒ½ä¼šæ²¡é’±ï¼‰"

        return reply, history_state, balance_status_value

    except Exception as e:
        err = str(e)
        if "402" in err or "Insufficient Balance" in err:
            balance_status_value = "â¤ï¸ å¼€å‘è€…è´¦æˆ·çŠ¶æ€ï¼šä½™é¢ä¸è¶³"
            return "ğŸ’¸ å¼€å‘è€…è´¦æˆ·é‡Œæ²¡é’±äº† ğŸ˜‚", history_state, balance_status_value
        return f"âŒ è°ƒç”¨ DeepSeek æ—¶å‡ºé”™ï¼š{e}", history_state, balance_status_value


# =====================
# ç¾¤èŠè°ƒç”¨ï¼šéšæœº 1ï½4 å¥³å‹
# =====================
def call_group_chat(prompt, history_state, balance_status):
    global balance_status_value

    # éšæœºé€‰ 1~4 ä¸ªå¥³å‹
    girls = list(PERSONALITY_PROMPTS.keys())
    selected = random.sample(girls, random.randint(1, 4))

    client = OpenAI(api_key=DEFAULT_DEEPSEEK_KEY, base_url="https://api.deepseek.com")

    group_replies = []
    combined_text = ""

    # æ¯ä¸ªå¥³å‹æŒ‰ç…§å‰ä¸€ä¸ªå¥³å‹çš„è¯ç»§ç»­â€œæ¥åŠ›â€
    previous_replies = []  # å­˜å‚¨ä¹‹å‰æ‰€æœ‰å¥³å‹çš„å›å¤

    for girl in selected:
        system_prompt = f"""
ä½ æ˜¯ {girl}ï¼Œä»¥ä¸‹æ˜¯ä½ çš„äººæ ¼è®¾å®šï¼š
{PERSONALITY_PROMPTS[girl]}

ã€ç¾¤èŠè¡Œä¸ºè§„åˆ™ã€‘
- ä¸è¦é‡å¤å¼•ç”¨ç”¨æˆ·åŸè¯ã€‚
- ä¸è¦è¯´â€œä½ è¯´ä½ è‚šå­ç–¼â€è¿™ç§å¤šä½™å†…å®¹ã€‚
- å¦‚æœä¹‹å‰å·²æœ‰å¥³å‹å‘è¨€ï¼Œä½ å¯ä»¥è½»å¾®åœ°æ¥è¯ï¼Œä½†ä¸è¦äº’ç›¸æ”»å‡»ã€‚
- å›å¤è¦ç®€çŸ­ã€æœ‰ä¸ªæ€§ã€‚
- åªè¾“å‡ºä½ è‡ªå·±çš„ä¸€å¥æˆ–å‡ å¥å›ç­”ï¼Œä¸è¦ç®¡å…¶ä»–äººã€‚
"""

        # æ„å»ºå¯¹è¯è®°å½•ï¼ˆè®© AI èƒ½æ¥ä¸Šå‰ä¸€ä¸ªäººçš„è¯ï¼‰
        messages = [{"role": "system", "content": system_prompt}]

        # ç”¨æˆ·é—®é¢˜åªç»™ä¸€æ¬¡
        messages.append({"role": "user", "content": prompt})

        # è®©æ¯ä¸ªå¥³å‹èƒ½çœ‹åˆ°å‰é¢æ‰€æœ‰å¥³å‹çš„å‘è¨€
        if previous_replies:
            context = "\n".join(previous_replies)
            messages.append({"role": "assistant", "content": f"å‰é¢çš„å¥³å‹ä»¬è¯´äº†ï¼š\n{context}\n\nç°åœ¨è½®åˆ°ä½ å›ç­”äº†ã€‚"})

        try:
            res = client.chat.completions.create(
                model=MODEL_NAME,
                messages=messages,
                max_tokens=300,
                temperature=0.8,
            )
            reply = res.choices[0].message.content.strip()
        except Exception as e:
            reply = f"ï¼ˆè°ƒç”¨å¤±è´¥ï¼š{e}ï¼‰"

        # æ ¼å¼åŒ–å›å¤ï¼Œæ·»åŠ å¥³å‹åå­—
        formatted_reply = f"**{girl}**\n{reply}"

        group_replies.append(formatted_reply)
        previous_replies.append(f"{girl}: {reply}")
        combined_text += formatted_reply + "\n\n"

    # è®°å½• Token
    history_state["used_tokens"] += estimate_tokens(prompt) + estimate_tokens(combined_text)
    history_state["messages"].append((prompt, combined_text))

    return group_replies, history_state, balance_status_value

# =====================
# è¾“å…¥å¤„ç†
# =====================
def user_input_fn(user_text, chat_history, history_state, branch_btns, personality, balance_status):
    user_text = (user_text or "").strip()
    if not user_text:
        return "", chat_history, gr.update(visible=False), history_state, balance_status

    if not history_state:
        history_state = {"messages": [], "used_tokens": 0}

    # é¢åº¦é™åˆ¶
    if history_state["used_tokens"] + estimate_tokens(user_text) > MAX_USER_TOKENS:
        return "ğŸ˜µâ€ğŸ’« è¶…å‡ºé¢åº¦å•¦ï¼Œä¸‹æ¬¡å†ç”¨å§ï¼", chat_history, gr.update(visible=False), history_state, balance_status

    chat_history = chat_history or []

    # ========= ç¾¤èŠæ¨¡å¼ =========
    if personality == "å½å½å–³å–³ç¾¤èŠ":
        # è°ƒç”¨ç¾¤èŠï¼Œè·å–æ¯ä¸ªå¥³å‹çš„å›å¤
        group_replies, history_state, balance_status = call_group_chat(user_text, history_state, balance_status)

        # å…ˆæ˜¾ç¤ºç”¨æˆ·è¾“å…¥ï¼ˆåªæœ‰ç¬¬ä¸€ä¸ªå¥³å‹çš„å›å¤å’Œç”¨æˆ·è¾“å…¥é…å¯¹ï¼‰
        if group_replies:
            chat_history.append((user_text, group_replies[0]))

            # å…¶ä½™å¥³å‹çš„å›å¤å•ç‹¬æ˜¾ç¤ºï¼ˆç”¨ç‰¹æ®Šæ ‡è®°å ä½ï¼‰
            for reply in group_replies[1:]:
                chat_history.append(("ã€€", reply))  # ä½¿ç”¨å…¨è§’ç©ºæ ¼ä½œä¸ºå ä½ç¬¦

        return "", chat_history, gr.update(visible=False), history_state, balance_status

    # ========= å•äººæ ¼æ¨¡å¼ =========
    reply, history_state, balance_status = call_deepseek(user_text, history_state, personality, balance_status)
    chat_history.append((user_text, reply))

    # æå–åˆ†æ”¯
    options = re.findall(r"[-â€¢]\s*(.*)", reply)
    if options:
        cleaned = [o.strip() for o in options if len(o.strip()) > 2][:3]
        return "", chat_history, gr.update(choices=cleaned, value=None, visible=True), history_state, balance_status

    return "", chat_history, gr.update(visible=False), history_state, balance_status


# =====================
# é€‰æ‹©åˆ†æ”¯
# =====================
def choose_branch_fn(selected, chat_history, history_state, branch_btns, personality, balance_status):
    if not selected:
        return chat_history, gr.update(visible=False), history_state, balance_status

    message = f"æˆ‘å€¾å‘äºï¼š{selected}"

    # ç¾¤èŠä¸æ”¯æŒåˆ†æ”¯
    if personality == "å½å½å–³å–³ç¾¤èŠ":
        group_replies, history_state, balance_status = call_group_chat(message, history_state, balance_status)
        for name, rep in group_replies:
            chat_history.append((f"{message}ï¼ˆâ†’ {name}ï¼‰", rep))
        return chat_history, gr.update(visible=False), history_state, balance_status

    # å•äººæ ¼åˆ†æ”¯
    reply, history_state, balance_status = call_deepseek(message, history_state, personality, balance_status)
    chat_history.append((message, reply))

    # æå–åˆ†æ”¯
    options = re.findall(r"[-â€¢]\s*(.*)", reply)
    if options:
        cleaned = [o.strip() for o in options][:3]
        return chat_history, gr.update(choices=cleaned, value=None, visible=True), history_state, balance_status

    return chat_history, gr.update(visible=False), history_state, balance_status


# =====================
# æ¸…ç©º
# =====================
def clear_all():
    return [], gr.update(visible=False), [], balance_status_value


# =====================
# Gradio UI
# =====================
with gr.Blocks(theme=gr.themes.Soft(primary_hue="violet"), css="""
#balance_status .value {
    font-size: 14px !important;
    font-weight: normal !important;
}
#chatbot .user { background-color: #f0f0f0; border-radius:12px; padding:6px; }
#chatbot .assistant { border-radius:12px; padding:6px; }
/* éšè—åªåŒ…å«å…¨è§’ç©ºæ ¼çš„ç”¨æˆ·æ¶ˆæ¯æ¡† */
.message.user .prose:empty,
.message.user .prose:has(br:only-child) {
    display: none !important;
}
.message.user:has(.prose:empty) {
    min-height: 0 !important;
    padding: 0 !important;
    margin: 0 !important;
}
""") as demo:

    gr.Markdown("## ğŸ’¬ ä½ çš„å¤©æ‰å¥³å‹ä»¬ï¼ˆå«å½å½å–³å–³ç¾¤èŠï¼‰")

    with gr.Row():
        with gr.Column(scale=3):
            personality_dropdown = gr.Dropdown(
                choices=["çŸ¥æ€§å§å§", "ä¸§æ°”å®…å¥³", "é˜³å…‰Eäºº", "æ¯’èˆŒå¾¡å§", "å½å½å–³å–³ç¾¤èŠ"],
                value="çŸ¥æ€§å§å§",
                label="é€‰æ‹©äººæ ¼"
            )
            chatbot = gr.Chatbot(label="å¤©æ‰å¥³å‹", height=520, type="tuples")
            branch_btns = gr.Radio(choices=[], label="ğŸ’­ å¯è€ƒè™‘æ–¹å‘ï¼š", interactive=True, visible=False)

            with gr.Row():
                msg = gr.Textbox(placeholder="ä½ æƒ³ä»€ä¹ˆå‘¢ï¼Ÿ...", label="ä½ çš„è¾“å…¥", scale=10, show_label=False, container=False)
                send_btn = gr.Button("ğŸ“¨", scale=1, variant="primary", min_width=50)

            clear = gr.Button("ğŸ§¹ æ¸…ç©ºå¯¹è¯")
            history_state = gr.State([])

        with gr.Column(scale=1):
            balance_status = gr.Label(value=balance_status_value, label="å¼€å‘è€…ä½™é¢çŠ¶æ€", elem_id="balance_status")

    msg.submit(
        user_input_fn,
        inputs=[msg, chatbot, history_state, branch_btns, personality_dropdown, balance_status],
        outputs=[msg, chatbot, branch_btns, history_state, balance_status]
    )

    send_btn.click(
        user_input_fn,
        inputs=[msg, chatbot, history_state, branch_btns, personality_dropdown, balance_status],
        outputs=[msg, chatbot, branch_btns, history_state, balance_status]
    )

    branch_btns.change(
        choose_branch_fn,
        inputs=[branch_btns, chatbot, history_state, branch_btns, personality_dropdown, balance_status],
        outputs=[chatbot, branch_btns, history_state, balance_status]
    )

    clear.click(clear_all, outputs=[chatbot, branch_btns, history_state, balance_status])

demo.launch(server_name="0.0.0.0", server_port=7860)
